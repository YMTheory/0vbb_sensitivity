{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888425dc-0abe-40b4-89b2-fc9329edd829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sys, then tell python where to find the nEXO-specific classes\n",
    "import sys\n",
    "sys.path.append('../../../modules')\n",
    "# sys.path.append('/Users/sangiorgio1/SoftwareProjects/sensitivity/modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3130b1-ab47-4bb6-961f-8156f37ae186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful libraries for analysis\n",
    "import pandas as pd\n",
    "from hist import Hist\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from pathlib import Path \n",
    "import hashlib\n",
    "import itertools\n",
    "import glob\n",
    "import io\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.set_context('poster')\n",
    "\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.rcParams['figure.figsize'] = (10,8)\n",
    "\n",
    "from cycler import cycler\n",
    "plt.rcParams['axes.prop_cycle'] = cycler(color='bgrcmyk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da540b83-4617-4ecf-a315-9c8c898a4ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the nEXO sensitivity classes\n",
    "import nEXOFitWorkspace\n",
    "import nEXOFitModel\n",
    "import nEXOFitLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc72124-f8af-4a1c-9781-7db0bb085600",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = Path('/p/lustre2/nexouser/samuele/siteselection')\n",
    "components_table_dir = Path('/p/lustre2/nexouser/samuele/multivarstudy/ComponentsTables')\n",
    "outputdir = basedir / 'output'\n",
    "plotdir = Path('plots')\n",
    "os.makedirs(plotdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7bf241-66e6-47b9-bb13-77baa428ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fit_results(tag, s = None):\n",
    "    h5_files = glob.glob(f'{outputdir}/*{tag}*.h5')\n",
    "    if h5_files:\n",
    "        print(f'Loading data for tag {tag}')\n",
    "        if s: print(s)\n",
    "        df_list = [pd.read_hdf(outputdir/Path(filename)) for filename in h5_files]\n",
    "        df_tmp = pd.concat(df_list, ignore_index=True)\n",
    "        print(f'---> Loaded {len(df_tmp)} toy datasets')\n",
    "        return df_tmp\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268a8cfd-7703-451e-b669-14b647d6a528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expected_counts():\n",
    "\n",
    "    # Note that I use ComponentsTable and Config file that define a much finer binning\n",
    "    config = '/g/g92/samuele/nEXO/sensitivity/work/SensitivityPaper2020_scripts/' \\\n",
    "             'SiteSelectionStudy/Sensitivity2020_Optimized_DNN_Standoff_Binning_version1_fineBinning_Xe137.yaml'\n",
    "    input_table = components_table_dir / f'ComponentsTable_D-024_DNN_factor=0.0_ERes=0.008.h5'    \n",
    "\n",
    "    if not input_table.is_file(): \n",
    "        print(f\"file not exists: {input_table}\")\n",
    "        return\n",
    "\n",
    "    workspace = nEXOFitWorkspace.nEXOFitWorkspace(config)\n",
    "    workspace.LoadComponentsTableFromFile(input_table)\n",
    "\n",
    "    for index, row in workspace.df_components.iterrows():\n",
    "    # Scale the gamma ray background components, except radon\n",
    "        # isotopes_to_leave_alone = ['Ar42', 'Xe137', 'bb2n', 'bb0n', 'B8nu', 'Rn222', ]  # just for bookkeeping\n",
    "        # isotopes_to_scale = ['K40', 'Co60', 'Al26', 'Th232', 'U238', 'Cs137']\n",
    "        # # The format is <isotope>_<part>, e.g. \"Th232_HVCables\"\n",
    "        # if row['PDFName'].split('_')[0] in isotopes_to_scale:\n",
    "        #     print(f'Scaling {row[\"PDFName\"]}...')\n",
    "        #     workspace.df_components.loc[index, 'SpecActiv'] = bkg_scale_factor * row['SpecActiv']\n",
    "        #     workspace.df_components.loc[index, 'SpecActivErr'] = bkg_scale_factor * row['SpecActivErr']\n",
    "\n",
    "        # Scale the Xe137 to the mean of the specified config distribution if present.\n",
    "        # This is needed so the initial guesses are properly set\n",
    "        if ('Xe137' in row['PDFName']) and ('Xe137Distribution' in workspace.config):\n",
    "            # pass\n",
    "            print(f'Setting {row[\"PDFName\"]}...')\n",
    "            counts = np.array(workspace.config['Xe137Distribution']['counts'])\n",
    "            bin_centers = np.array(workspace.config['Xe137Distribution']['bin_centers'])\n",
    "            mean_xe137_dist = sum(counts * bin_centers)/sum(counts) * 1000 / (365. * 24 * 3600)\n",
    "            workspace.df_components.loc[index, 'SpecActiv'] = mean_xe137_dist\n",
    "            workspace.df_components.loc[index, 'SpecActivErr'] = mean_xe137_dist\n",
    "\n",
    "    workspace.CreateGroupedPDFs()\n",
    "\n",
    "    # Define the ROI within the workspace\n",
    "    # Note that the ROI energy depends on the resolution since it's +/- FWHM/2\n",
    "    # The DNN cut is set at the value for 85% signal efficiency\n",
    "    fwhm = 2457 * 0.008 * 2.35\n",
    "    roi_dict = {'DNN': [0.83, 1.],   # see values in the multivariation study tech note\n",
    "                'Energy (keV)': [2457. - fwhm/2., 2457. + fwhm/2.],\n",
    "                'Standoff (mm)': [104.5, 650.]}\n",
    "    # roi_dict = {'DNN': [0.85, 1.],\n",
    "    #         'Energy (keV)': [2434., 2480.],\n",
    "    #         'Standoff (mm)': [104.5, 650.]}\n",
    "    workspace.DefineROI(roi_dict)\n",
    "#         print(workspace.df_components.loc[0])\n",
    "\n",
    "    # Create the likelihood object\n",
    "    likelihood = nEXOFitLikelihood.nEXOFitLikelihood()\n",
    "    likelihood.AddPDFDataframeToModel(workspace.df_group_pdfs, workspace.histogram_axis_names)\n",
    "\n",
    "    initial_guess = likelihood.GetVariableValues()\n",
    "\n",
    "    # Scale the Rn222 component according to the input value\n",
    "    # rn222_idx = likelihood.model.GetVariableIndexByName('Rn222')\n",
    "    # initial_guess[rn222_idx] *= rn222_scale_factor\n",
    "\n",
    "    # Update the model in the likelihood object\n",
    "    likelihood.model.UpdateVariables(initial_guess)\n",
    "    likelihood.model.GenerateModelDistribution()\n",
    "\n",
    "    # Print out the number of events in the ROI\n",
    "    total_bkg_in_roi = likelihood.model.GetIntegralInBinRange(workspace.GetROIBinIndices())\n",
    "    output_str = f'TotalROIBkg: {total_bkg_in_roi} cts/10 y\\n'\n",
    "\n",
    "    for component in likelihood.model.variable_list:\n",
    "        if 'Shape' in component['Name']:\n",
    "            continue\n",
    "        num_counts_in_roi = likelihood.model.GetComponentIntegralInBinRange(\n",
    "            component['Name'], workspace.GetROIBinIndices())\n",
    "        # df.at[tag, component['Name']] = num_counts_in_roi\n",
    "        output_str += f'{component[\"Name\"] + \":\":<20}\\t'\n",
    "        output_str += f'{num_counts_in_roi:>10.4}\\t'\n",
    "        output_str += f'{int(1000 * num_counts_in_roi / total_bkg_in_roi) / 10.:>10.4}%\\n'\n",
    "    return output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01957baa-5476-4ef0-a63a-8ddddf9ab4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = load_fit_results(\"LNGS_RV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f250a3-8a16-4c3c-ac7e-19811986d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c26952-ed4f-44e2-92d0-ff7bb7f8f90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with redirect_stdout(io.StringIO()):    # capture output so it won't pollute the terminal\n",
    "    with redirect_stderr(io.StringIO()):\n",
    "        output_str = get_expected_counts()\n",
    "print(output_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9040160-6dd7-45f7-814c-9a9a63b01e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_good_fit_mask(df_fit):\n",
    "    good_fit_mask = []\n",
    "    for index,row in df_fit.iterrows():\n",
    "        if np.sum(row['fixed_fit_acc_covar']) < len(row['fixed_fit_acc_covar'])-2 \\\n",
    "            or not row['best_fit_covar'] \\\n",
    "            or row['90CL_crossing'] < 0.01\\\n",
    "            or row['best_fit_nll'] > 0.:\n",
    "            good_fit_mask.append(False)\n",
    "        else:\n",
    "            good_fit_mask.append(True)\n",
    "    return good_fit_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d90c7dd-7677-48e4-9d93-c6d337f41e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_fit_mask = get_good_fit_mask(res)\n",
    "convergence_f = np.sum(good_fit_mask)/len(res)\n",
    "print(f'Convergence fraction: {convergence_f:3.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ec4c43-4c11-4f82-bf92-22f18519bb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xe137_best_fits = [r['Num_Xe137_and_Ar42'] for r in res['best_fit_parameters'].loc[good_fit_mask]]\n",
    "Xe137_best_fits = np.array(Xe137_best_fits)/10.\n",
    "fig, ax = plt.subplots()\n",
    "h = Hist.new.Regular(121, min(Xe137_best_fits), max(Xe137_best_fits), name=\"signal_counts\").Double()\n",
    "h.fill(Xe137_best_fits)\n",
    "median = np.median(Xe137_best_fits)\n",
    "print(f'{median:.3f}')\n",
    "\n",
    "h.plot1d(ax=ax,)\n",
    "\n",
    "# plt.legend()\n",
    "plt.xlabel('Xe137+Ar42 component best fit [cts/y]')\n",
    "# plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61693603-a6c8-40bb-a54a-864e0ec5a683",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xe137_input = [r[-1] for r in res['input_parameters'].loc[good_fit_mask]]\n",
    "Xe137_input = np.array(Xe137_input)/10.\n",
    "# print(Xe137_input, min(Xe137_input), max(Xe137_input)  )\n",
    "fig, ax = plt.subplots()\n",
    "h = Hist.new.Regular(121, min(Xe137_input), max(Xe137_input), name=\"signal_counts\").Double()\n",
    "h.fill(Xe137_input)\n",
    "median = np.median(Xe137_input)\n",
    "print(f'{median:.3f}')\n",
    "\n",
    "h.plot1d(ax=ax,)\n",
    "\n",
    "# plt.legend()\n",
    "plt.xlabel('Xe137+Ar42 component total integral > 700 keV [cts/y]')\n",
    "# plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fec684-e7af-493b-9102-1449c055353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_atoms_136(enrichment_fraction=0.9):\n",
    "    \"\"\" Number of Xe136 atoms in nEXO fiducial volume \"\"\"\n",
    "    mmass134 = 0.133905395  # kg/mol 134\n",
    "    mmass136 = 0.135907219  # kg/mol 136\n",
    "    at_frac = enrichment_fraction           # atomic fraction 136 / (136 + 134)\n",
    "    avog_num = 6.022141E23  # Avogadro's number\n",
    "    fid_mass = 3281         # mass of fiducial volume [kg]\n",
    "\n",
    "    atoms136 = (fid_mass * avog_num * at_frac) / ((mmass136 * at_frac) + ((1 - at_frac) * mmass134))\n",
    "\n",
    "    return atoms136\n",
    "\n",
    "\n",
    "def ComputeHalflifeFromNumCounts(counts, enrichment_fraction=0.9, lifetime=10):\n",
    "    \"\"\"Calculate the sensitivity of nEXO in terms of half-life (years)\"\"\"\n",
    "    atoms136 = calc_atoms_136(enrichment_fraction)\n",
    "    eff = 0.9598  # hit efficiency\n",
    "    sensitivity = eff * atoms136 * lifetime * np.log(2) / counts\n",
    "    return sensitivity\n",
    "\n",
    "\n",
    "def ComputeCountsFromHalflife(sensitivity, enrichment_fraction=0.9, lifetime=10):\n",
    "    \"\"\"Calculate the sensitivity of nEXO in terms of half-life (years)\"\"\"\n",
    "    atoms136 = calc_atoms_136(enrichment_fraction)\n",
    "    eff = 0.9598  # hit efficiency\n",
    "    counts = eff * atoms136 * lifetime * np.log(2) / sensitivity\n",
    "    return counts\n",
    "    \n",
    "\n",
    "# def ComputeHalflifeFromNumCounts( counts, enrichment_fraction=0.9 ):\n",
    "#     '''Returns the half life which would give (on average) the input number of signal counts'''\n",
    "    \n",
    "#     N_A = 6.02e23 # atoms/mol\n",
    "#     FidMass = 3281 # kg\n",
    "#     AtomicMass = 135.8 # g/mol\n",
    "#     SigEfficiency = 0.96\n",
    "#     Livetime = 10 # years\n",
    "#     return FidMass*1.e3 / AtomicMass * N_A * enrichment_fraction * Livetime * \\\n",
    "#             SigEfficiency * np.log(2) / counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be47226-4eb1-4233-b905-87c8dd798c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Median [cts]\\tSensitivity [y]')\n",
    "fig, ax = plt.subplots()\n",
    "h = Hist.new.Regular(121, 0, 60, name=\"signal_counts\").Double()\n",
    "values = res['90CL_crossing'].loc[good_fit_mask]\n",
    "h.fill(values)\n",
    "median = np.median(values)\n",
    "sens = ComputeHalflifeFromNumCounts(median)\n",
    "print(f'{median:.3f}\\t{sens:.3e}')\n",
    "#     print(f'Results for tag {tag}')\n",
    "#     print(f'   Median 90%CL on signal counts: {median:.3f}')\n",
    "#     print(f'   Sensitivity: {df.at[tag, \"sens\"]:.3e} years')\n",
    "\n",
    "h.plot1d(ax=ax,)\n",
    "\n",
    "# plt.legend()\n",
    "plt.xlabel('90% CL on signal counts for given toy')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847826f6-cb10-4d4b-96e3-83bf65015b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nEXO VirtualEnv",
   "language": "python",
   "name": "nexo_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
