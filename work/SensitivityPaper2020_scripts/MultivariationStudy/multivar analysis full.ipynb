{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0becc0a8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import sys, then tell python where to find the nEXO-specific classes\n",
    "import sys\n",
    "sys.path.append('../../../modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f79d9a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import useful libraries for analysis\n",
    "import pandas as pd\n",
    "import hist\n",
    "from hist import Hist\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from pathlib import Path \n",
    "import hashlib\n",
    "import itertools\n",
    "import glob\n",
    "import io\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.set_context('poster')\n",
    "\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.rcParams['figure.figsize'] = (10,8)\n",
    "\n",
    "from cycler import cycler\n",
    "plt.rcParams['axes.prop_cycle'] = cycler(color='bgrcmyk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a46dcb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import the nEXO sensitivity classes\n",
    "import nEXOFitWorkspace\n",
    "import nEXOFitModel\n",
    "import nEXOFitLikelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950e02b5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609f03df",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "basedir = Path('/p/lustre2/nexouser/samuele/multivarstudy')\n",
    "outputdir = basedir / 'output'\n",
    "plotdir = Path('plots')\n",
    "os.makedirs(plotdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff97a11d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import dnn smoothing results obtained from the dnn_smoothing notebook\n",
    "dnn_factors_df = pd.read_csv('dnn_smoothing_results.csv')\n",
    "dnn_factors_df = dnn_factors_df.set_index('dnn_f')\n",
    "\n",
    "# Set default value based on chosen signal efficiency \n",
    "signal_efficiency = 80\n",
    "dnn_factors_df['dnn_cut_value'] = dnn_factors_df[f'dnn_cut_value_{signal_efficiency}']\n",
    "dnn_factors_df['bkg_misID'] = dnn_factors_df[f'bkg_misID_{signal_efficiency}']\n",
    "\n",
    "display(dnn_factors_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef88b214",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dnn_factors = dnn_factors_df.index\n",
    "xe137_scale_factors = [1., 1.2, 1.5, 2., ]     # 1., 1.2, 1.5, 2., 3., \n",
    "rn222_scale_factors = [1., 1.2, 1.5, 2., ]     # 1., 1.2, 1.5, 2., 3., \n",
    "bkg_scale_factors = [1., 1.2, 1.5, 2., ]       # 1., 1.2, 1.5, 2., 3., \n",
    "energy_res_factors = [0.008, 0.01, 0.011, 0.012, 0.014]  # 0.008, 0.01, 0.011, 0.012, 0.014\n",
    "\n",
    "df = pd.DataFrame(columns=['tag', 'dnn_f', 'bkg_misID', 'xe137_f', 'rn222_f', 'bkg_f', \n",
    "                           'energy_res_f', 'convergence_f', \n",
    "                           'median', 'sens', 'sens_1e28'])\n",
    "df = df.set_index('tag')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3f66a5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results_file = Path('multivar_study_results.h5')\n",
    "# delete prior data if needed by uncommenting the following line\n",
    "# this will result in all data being reloaded which may take some time:\n",
    "# results_file.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a57503e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load prior data if available\n",
    "if results_file.is_file():\n",
    "    df = pd.read_hdf(results_file) \n",
    "#     display(df)\n",
    "# df = df.drop(index=['4A78FC', '1E85A6', 'AD42F2'])\n",
    "existing_tags = df.index\n",
    "print(existing_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8754456",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_tag(xe137_scale_factor, rn222_scale_factor, dnn_scale_factor, bkg_scale_factor, energy_res):\n",
    "    # This should match the hash string used in Compute90PercentLimit script \n",
    "    # FIXME: hash should not be calculated both here and Compute90PercentLimit\n",
    "    s = f'Xe137:{xe137_scale_factor:0>4.4f} ' + \\\n",
    "        f'Rn222:{rn222_scale_factor:0>4.4f} ' + \\\n",
    "        f'DNN:{dnn_scale_factor:0>4.4f} ' + \\\n",
    "        f'Bkg:{bkg_scale_factor:0>4.4f} ' + \\\n",
    "        f'ERes:{energy_res:0>4.4f}'\n",
    "    return hashlib.md5(s.encode('utf-8')).hexdigest()[:6].upper(), s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e588432",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_expected_counts(df, xe137_scale_factor, rn222_scale_factor, dnn_f, bkg_scale_factor, energy_res_f):\n",
    "    \n",
    "    # Note that I use ComponentsTable and Config file that define a much finer binning\n",
    "    config = '/g/g92/samuele/nEXO/sensitivity/work/SensitivityPaper2020_scripts/' \\\n",
    "             'MultivariationStudy/Sensitivity2020_Optimized_DNN_Standoff_Binning_version1_fineBinning.yaml'\n",
    "    input_table = basedir / 'ComponentsTables' / f'ComponentsTable_D-024_DNN_factor={dnn_f}_ERes={energy_res_f}_fineBinning.pkl.gz'    \n",
    "    \n",
    "    if not input_table.is_file(): \n",
    "        return\n",
    "    \n",
    "    tag, s = get_tag(xe137_scale_factor, rn222_scale_factor, dnn_f, bkg_scale_factor, energy_res_f)\n",
    "\n",
    "#     h5_files = glob.glob(f'{outputdir}/*{tag}*.h5')\n",
    "    \n",
    "#     if h5_files:\n",
    "    workspace = nEXOFitWorkspace.nEXOFitWorkspace(config)\n",
    "    workspace.LoadComponentsTableFromFile(input_table)\n",
    "\n",
    "    for index, row in workspace.df_components.iterrows():\n",
    "    # Scale the gamma ray background components, except radon\n",
    "        isotopes_to_leave_alone = ['Ar42', 'Xe137', 'bb2n', 'bb0n', 'B8nu', 'Rn222', ]  # just for bookkeeping\n",
    "        isotopes_to_scale = ['K40', 'Co60', 'Al26', 'Th232', 'U238', 'Cs137']\n",
    "        # The format is <isotope>_<part>, e.g. \"Th232_HVCables\"\n",
    "        if row['PDFName'].split('_')[0] in isotopes_to_scale:\n",
    "            print(f'Scaling {row[\"PDFName\"]}...')\n",
    "            workspace.df_components.loc[index, 'SpecActiv'] = bkg_scale_factor * row['SpecActiv']\n",
    "            workspace.df_components.loc[index, 'SpecActivErr'] = bkg_scale_factor * row['SpecActivErr']\n",
    "\n",
    "        # Scale the Xe137 and Ar42 components.\n",
    "        if 'Xe137' in row['PDFName'] or 'Ar42' in row['PDFName']:\n",
    "            workspace.df_components.loc[index, 'SpecActiv'] = xe137_scale_factor * row['SpecActiv']\n",
    "            workspace.df_components.loc[index, 'SpecActivErr'] = xe137_scale_factor * row['SpecActivErr']\n",
    "\n",
    "    workspace.CreateGroupedPDFs()\n",
    "\n",
    "    # Define the ROI within the workspace\n",
    "    # Note that the ROI energy depends on the resolution since it's +/- FWHM/2\n",
    "    # The DNN cut is set at the value for 85% signal efficiency\n",
    "    fwhm = 2457 * energy_res_f * 2.35\n",
    "    roi_dict = {'DNN': [dnn_factors_df.loc[dnn_f]['dnn_cut_value'], 1.],\n",
    "                'Energy (keV)': [2457. - fwhm/2., 2457. + fwhm/2.],\n",
    "                'Standoff (mm)': [104.5, 650.]}\n",
    "    workspace.DefineROI(roi_dict)\n",
    "#         print(workspace.df_components.loc[0])\n",
    "\n",
    "    # Create the likelihood object\n",
    "    likelihood = nEXOFitLikelihood.nEXOFitLikelihood()\n",
    "    likelihood.AddPDFDataframeToModel(workspace.df_group_pdfs, workspace.histogram_axis_names)\n",
    "\n",
    "    initial_guess = likelihood.GetVariableValues()\n",
    "\n",
    "    # Scale the Rn222 component according to the input value\n",
    "    rn222_idx = likelihood.model.GetVariableIndexByName('Rn222')\n",
    "    initial_guess[rn222_idx] *= rn222_scale_factor\n",
    "\n",
    "    # Update the model in the likelihood object\n",
    "    likelihood.model.UpdateVariables(initial_guess)\n",
    "    likelihood.model.GenerateModelDistribution()\n",
    "\n",
    "    # Print out the number of events in the ROI\n",
    "    df.at[tag, 'TotalROIBkg'] = likelihood.model.GetIntegralInBinRange(workspace.GetROIBinIndices())\n",
    "\n",
    "    for component in likelihood.model.variable_list:\n",
    "        if 'Shape' in component['Name']:\n",
    "            continue\n",
    "        num_counts_in_roi = likelihood.model.GetComponentIntegralInBinRange(\n",
    "            component['Name'], workspace.GetROIBinIndices())\n",
    "        df.at[tag, component['Name']] = num_counts_in_roi\n",
    "#         print(f'{component[\"Name\"] + \":\":<20}\\t'\n",
    "#               f'{num_counts_in_roi:>10.4}\\t'\n",
    "#               f'{int(1000 * num_counts_in_roi / total_bkg_in_roi) / 10.:>10.4}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957476ec",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bd7952",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_fit_results(tag, s = None):\n",
    "    h5_files = glob.glob(f'{outputdir}/*{tag}*.h5')\n",
    "    if h5_files:\n",
    "        print(f'Loading data for tag {tag}')\n",
    "        if s: print(s)\n",
    "        df_list = [pd.read_hdf(outputdir/Path(filename)) for filename in h5_files]\n",
    "        df_tmp = pd.concat(df_list, ignore_index=True)\n",
    "        print(f'---> Loaded {len(df_tmp)} toy datasets')\n",
    "        return df_tmp\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725e76c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dfdict = dict()\n",
    "for dnn_scale_factor, xe137_scale_factor, rn222_scale_factor, bkg_scale_factor, energy_res \\\n",
    "        in itertools.product(dnn_factors, xe137_scale_factors, rn222_scale_factors, bkg_scale_factors,\n",
    "                             energy_res_factors):\n",
    "\n",
    "    tag, s = get_tag(xe137_scale_factor, rn222_scale_factor, dnn_scale_factor, bkg_scale_factor, energy_res)\n",
    "    \n",
    "    if tag not in existing_tags: \n",
    "    \n",
    "        res = load_fit_results(tag)\n",
    "\n",
    "        if res is not None:\n",
    "            dfdict[tag] = res\n",
    "            data = {'dnn_f':dnn_scale_factor, 'bkg_misID':dnn_factors_df.loc[dnn_scale_factor]['bkg_misID'],\n",
    "                    'xe137_f':xe137_scale_factor, 'rn222_f':rn222_scale_factor, \n",
    "                    'bkg_f':bkg_scale_factor, 'energy_res_f':energy_res, }\n",
    "            df.loc[tag] = data\n",
    "        \n",
    "    \n",
    "        if tag in df.index:\n",
    "            with redirect_stdout(io.StringIO()):    # capture output so it won't pollute the terminal\n",
    "                with redirect_stderr(io.StringIO()):\n",
    "                    get_expected_counts(df, xe137_scale_factor, rn222_scale_factor, dnn_scale_factor, bkg_scale_factor, energy_res)  \n",
    "            print(f\"---> Loaded expected counts for {tag}. Total ROI counts: {df.at[tag, 'TotalROIBkg']}\")\n",
    "            print('---------------------------')\n",
    "\n",
    "#     else:\n",
    "#         print(f'No data found for tag {tag}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b446f0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50777372",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df_tmp = dfdict['A516CD']\n",
    "# df_tmp.head()\n",
    "# print(\"Number of Toys:\", len(df_tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488a55b4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Compute the convergence fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b217537d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_good_fit_mask(df_fit):\n",
    "    good_fit_mask = []\n",
    "    for index,row in df_fit.iterrows():\n",
    "        if np.sum(row['fixed_fit_acc_covar']) < len(row['fixed_fit_acc_covar'])-2 \\\n",
    "            or not row['best_fit_covar'] \\\n",
    "            or row['90CL_crossing'] < 0.01\\\n",
    "            or row['best_fit_nll'] > 0.:\n",
    "            good_fit_mask.append(False)\n",
    "        else:\n",
    "            good_fit_mask.append(True)\n",
    "    return good_fit_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ef3ba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "good_fit_mask_dict = {}\n",
    "for tag, df_fit in dfdict.items():\n",
    "    if tag in existing_tags: continue  # don't process if already exists in dataframe\n",
    "    good_fit_mask = get_good_fit_mask(df_fit)\n",
    "    convergence_f = np.sum(good_fit_mask)/len(df_fit)\n",
    "    print(f'Tag {tag} convergence fraction: {convergence_f:3.3}')\n",
    "    df.at[tag, 'convergence_f'] = convergence_f\n",
    "    good_fit_mask_dict[tag] = good_fit_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea80b9fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "display(df.loc[df['convergence_f']<0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5873bf79",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Compute Median and 90% CL Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783515ef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calc_atoms_136(enrichment_fraction=0.9):\n",
    "    \"\"\" Number of Xe136 atoms in nEXO fiducial volume \"\"\"\n",
    "    mmass134 = 0.133905395  # kg/mol 134\n",
    "    mmass136 = 0.135907219  # kg/mol 136\n",
    "    at_frac = enrichment_fraction           # atomic fraction 136 / (136 + 134)\n",
    "    avog_num = 6.022141E23  # Avogadro's number\n",
    "    fid_mass = 3281         # mass of fiducial volume [kg]\n",
    "\n",
    "    atoms136 = (fid_mass * avog_num * at_frac) / ((mmass136 * at_frac) + ((1 - at_frac) * mmass134))\n",
    "\n",
    "    return atoms136\n",
    "\n",
    "\n",
    "def ComputeHalflifeFromNumCounts(counts, enrichment_fraction=0.9, lifetime=10):\n",
    "    \"\"\"Calculate the sensitivity of nEXO in terms of half-life (years)\"\"\"\n",
    "    atoms136 = calc_atoms_136(enrichment_fraction)\n",
    "    eff = 0.9598  # hit efficiency\n",
    "    sensitivity = eff * atoms136 * lifetime * np.log(2) / counts\n",
    "    return sensitivity\n",
    "\n",
    "\n",
    "def ComputeCountsFromHalflife(sensitivity, enrichment_fraction=0.9, lifetime=10):\n",
    "    \"\"\"Calculate the sensitivity of nEXO in terms of half-life (years)\"\"\"\n",
    "    atoms136 = calc_atoms_136(enrichment_fraction)\n",
    "    eff = 0.9598  # hit efficiency\n",
    "    counts = eff * atoms136 * lifetime * np.log(2) / sensitivity\n",
    "    return counts\n",
    "    \n",
    "\n",
    "# def ComputeHalflifeFromNumCounts( counts, enrichment_fraction=0.9 ):\n",
    "#     '''Returns the half life which would give (on average) the input number of signal counts'''\n",
    "    \n",
    "#     N_A = 6.02e23 # atoms/mol\n",
    "#     FidMass = 3281 # kg\n",
    "#     AtomicMass = 135.8 # g/mol\n",
    "#     SigEfficiency = 0.96\n",
    "#     Livetime = 10 # years\n",
    "#     return FidMass*1.e3 / AtomicMass * N_A * enrichment_fraction * Livetime * \\\n",
    "#             SigEfficiency * np.log(2) / counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daa59d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Tag\\tMedian [cts]\\tSensitivity [y]')\n",
    "fig, ax = plt.subplots()\n",
    "for tag, df_fit in dfdict.items():\n",
    "    if tag in existing_tags: continue  # don't process if already exists in dataframe\n",
    "    h = Hist.new.Regular(121, 0, 60, name=\"signal_counts\").Double()\n",
    "    values = df_fit['90CL_crossing'].loc[good_fit_mask_dict[tag]]\n",
    "    h.fill(values)\n",
    "    median = np.median(values)\n",
    "    df.at[tag, 'median'] = median\n",
    "    df.at[tag, 'sens'] = ComputeHalflifeFromNumCounts(median)\n",
    "    print(f'{tag}\\t{median:.3f}\\t{df.at[tag, \"sens\"]:.3e}')\n",
    "#     print(f'Results for tag {tag}')\n",
    "#     print(f'   Median 90%CL on signal counts: {median:.3f}')\n",
    "#     print(f'   Sensitivity: {df.at[tag, \"sens\"]:.3e} years')\n",
    "\n",
    "    h.plot1d(ax=ax, label=f'{tag}')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('90% CL on signal counts for given toy')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc851183",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# format_mapping = {\"sens\": \"{:.3e}\", }\n",
    "# df.style.format(format_mapping)\n",
    "# df['sens_str'] = df['sens'].apply('{:.3e}'.format)\n",
    "df['sens_1e28'] = df['sens']/1e28\n",
    "df = df.sort_values(by=['sens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f4e1cd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "display(df)\n",
    "df.to_csv('multivar_study_results.csv')\n",
    "df.to_hdf(results_file, 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28f6c41",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "d = df.loc[df['xe137_f']==2.0]\n",
    "display(d)\n",
    "df_res_d = {}\n",
    "for e_res in [0.008, 0.01, 0.012]:\n",
    "    dd = d.loc[df['energy_res_f'] == e_res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cc7043",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c16e0f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Plots grouped by DNN Smearing factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31594628",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# colors = ['r', 'b', 'g', 'orange']\n",
    "colors = sns.color_palette('tab10')\n",
    "alphas = [1.0, 0.6, 0.4, 0.2]\n",
    "for i, dnn_f in enumerate([0., 0.15, 0.177, 0.2]):\n",
    "    d = df.loc[(df['dnn_f']==dnn_f) & (df['rn222_f'] == df['bkg_f']) & (df['rn222_f'] == df['xe137_f'])]\n",
    "    #display(d.sort_values(by=['energy_res_f']))\n",
    "    for j, bkg_f in enumerate([1.0, 1.2, 1.5, 2.0]):\n",
    "        dd = d.loc[df['bkg_f'] == bkg_f]\n",
    "        dd = dd.sort_values(by=['energy_res_f'])\n",
    "        if not len(dd): continue\n",
    "#         if bkg_f == 1.5:\n",
    "#             dt = df.loc[(df['dnn_f']==dnn_f) & (df['rn222_f'] == df['bkg_f']) & (df['xe137_f'] == 1.) & (df['bkg_f'] == bkg_f)]\n",
    "#             if len(dt):\n",
    "#                 plt.plot(dt.energy_res_f*100, dt.sens_1e28,'--s', color=colors[i], \n",
    "#                      markersize=10, linewidth=3, alpha=alphas[j], label=f\"Bkg_f: {bkg_f} (no Xe137 scaling)\") #DNN_f: {dnn_f}\n",
    "#                 for (x,y,z) in zip(dt.energy_res_f*100, dt.sens_1e28, dt.TotalROIBkg/10.):\n",
    "#                     if x == min(dt.energy_res_f)*100:\n",
    "#                         plt.gca().annotate(f'{z:.2f}', xy=(x,y), xytext=(5,5), textcoords='offset points', \n",
    "#                                            color=colors[i], fontsize=14)\n",
    "        plt.plot(dd.energy_res_f*100, dd.sens_1e28,'-o', color=colors[i], \n",
    "                 markersize=10, linewidth=3, alpha=alphas[j], label=f\"Bkg_f: {bkg_f}\") #DNN_f: {dnn_f}\n",
    "        for (x,y,z) in zip(dd.energy_res_f*100, dd.sens_1e28, dd.TotalROIBkg/10.):\n",
    "#             if x == min(dd.energy_res_f)*100:\n",
    "            plt.gca().annotate(f'{z:.2f}', xy=(x,y), xytext=(5,5), textcoords='offset points', \n",
    "                                   color=colors[i], fontsize=14)\n",
    "    \n",
    "    plt.gca().annotate(r'ROI Bkg values in units of SS cts/(FWHM$\\cdot$2000kg$\\cdot$y)'\n",
    "                       + '\\n' + fr'SS cut based on {signal_efficiency}% $0\\nu\\beta\\beta$ efficiency', \n",
    "                       xy=(9,6), xycoords='axes points', color=colors[i], fontsize=12)       \n",
    "    plt.xlim((0.75,1.45))    \n",
    "    plt.ylim((0.8,1.45))    \n",
    "    plt.title(f\"DNN Background MisID: {dnn_factors_df.loc[dnn_f]['bkg_misID']:.1f}% (f={dnn_f})\")\n",
    "    plt.xlabel(r'$\\sigma/E$ Energy Resolution [%]')\n",
    "    plt.ylabel(r'Halflife Sensitivity [$\\times 10^{28}$ yrs]')\n",
    "    handles, labels = plt.gca().get_legend_handles_labels() # get existing handles and labels\n",
    "    plt.legend(handles, labels, fontsize=16)\n",
    "    plt.axhline(y=1.0, color='black', linestyle='--', linewidth=3,)\n",
    "    plt.grid()\n",
    "    plt.savefig(plotdir / f'Multivar_study_by_DNN_{dnn_f}.png', bbox_inches = \"tight\", \n",
    "                transparent=False, facecolor='white', dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8a95dd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Plots grouped by Energy Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417ead7a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# colors = ['r', 'b', 'g', 'orange']\n",
    "colors = sns.color_palette('tab10')\n",
    "alphas = [1.0, 0.7, 0.5, 0.3]\n",
    "for i, energy_res_f in enumerate([0.008, 0.01, 0.011, 0.012]):\n",
    "    d = df.loc[(df['energy_res_f']==energy_res_f) & (df['rn222_f'] == df['bkg_f']) & (df['rn222_f'] == df['xe137_f'])]\n",
    "    #display(d.sort_values(by=['energy_res_f']))\n",
    "    for j, bkg_f in enumerate([1.0, 1.2, 1.5, 2.0]):\n",
    "        dd = d.loc[df['bkg_f'] == bkg_f]\n",
    "        dd = dd.sort_values(by=['bkg_misID'])\n",
    "        if not len(dd): continue\n",
    "#         if bkg_f == 1.5:\n",
    "#             dt = df.loc[(df['energy_res_f']==energy_res_f) & (df['rn222_f'] == df['bkg_f']) & (df['xe137_f'] == 1.) & (df['bkg_f'] == bkg_f)]\n",
    "#             if len(dt):\n",
    "#                 plt.plot(dt.bkg_misID, dt.sens_1e28,'--s', color=colors[i], \n",
    "#                      markersize=10, linewidth=3, alpha=alphas[j], label=f\"Bkg_f: {bkg_f} (no Xe137 scaling)\") #DNN_f: {dnn_f}\n",
    "#                 for (x,y,z) in zip(dt.bkg_misID, dt.sens_1e28, dt.TotalROIBkg/10.):\n",
    "#                     plt.gca().annotate(f'{z:.2f}', xy=(x,y), xytext=(5,5), textcoords='offset points', \n",
    "#                                        color=colors[i], fontsize=14)\n",
    "        plt.plot(dd.bkg_misID, dd.sens_1e28,'-o', color=colors[i], \n",
    "                 markersize=10, linewidth=3, alpha=alphas[j], label=f\"Bkg_f: {bkg_f}\") # , ERes: {energy_res_f}\n",
    "        for (x,y,z) in zip(dd.bkg_misID, dd.sens_1e28, dd.TotalROIBkg/10.):\n",
    "#             if x == min(dd.bkg_misID):\n",
    "              plt.gca().annotate(f'{z:.2f}', xy=(x,y), xytext=(5,5), textcoords='offset points', \n",
    "                                   color=colors[i], fontsize=14)\n",
    "\n",
    "    plt.gca().annotate(r'ROI Bkg values in units of SS cts/(FWHM$\\cdot$2000kg$\\cdot$y)'\n",
    "                       + '\\n' + fr'SS cut based on {signal_efficiency}% $0\\nu\\beta\\beta$ efficiency', \n",
    "                       xy=(9,6), xycoords='axes points', color=colors[i], fontsize=12)       \n",
    "    plt.xlim((None, 9.0))\n",
    "    plt.ylim((0.8, 1.45))    \n",
    "    plt.title(f'Energy Resolution: {energy_res_f*100:.1f}%')\n",
    "    plt.xlabel(fr'DNN Background MisID [%] at {signal_efficiency}% Signal ID')\n",
    "    plt.ylabel(r'Halflife Sensitivity [$\\times 10^{28}$ yrs]')\n",
    "    plt.legend(fontsize=16)\n",
    "    plt.axhline(y=1.0, color='black', linestyle='--', linewidth=3,)\n",
    "    plt.grid()\n",
    "    plt.savefig(plotdir / f'Multivar_study_by_ERes_{energy_res_f}.png', bbox_inches = \"tight\", \n",
    "                transparent=False, facecolor='white', dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46a04c5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Study convergence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eced5a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Given a vector V of length N, the median of V is the middle value \n",
    "# of a sorted copy of V, V_sorted - i e., V_sorted[(N-1)/2], when N \n",
    "# is odd, and the average of the two middle values of V_sorted when \n",
    "# N is even.\n",
    "# To speed things up, I use `sortedcontainers`\n",
    "from sortedcontainers import SortedList\n",
    "\n",
    "# for tag in ['8E1210', 'C8BAC8', 'C0FEAE', '800AAD']:\n",
    "for tag in df.loc[(df['energy_res_f'] == 0.011) & (df['dnn_f'] == 0.15)].index:\n",
    "    \n",
    "    if tag not in dfdict.keys():\n",
    "        h5_files = glob.glob(f'{outputdir}/*{tag}*.h5')\n",
    "        if h5_files:\n",
    "            df_list = [pd.read_hdf(outputdir/Path(filename)) for filename in h5_files]\n",
    "            dfdict[tag] = pd.concat(df_list, ignore_index=True)\n",
    "            \n",
    "    df_fit = dfdict[tag]\n",
    "    \n",
    "    good_fit_mask = []\n",
    "    for index,row in df_fit.iterrows():\n",
    "        if np.sum(row['fixed_fit_acc_covar']) < len(row['fixed_fit_acc_covar'])-2 \\\n",
    "            or not row['best_fit_covar'] \\\n",
    "            or row['90CL_crossing'] < 0.01\\\n",
    "            or row['best_fit_nll'] > 0.:\n",
    "            good_fit_mask.append(False)\n",
    "        else:\n",
    "            good_fit_mask.append(True)\n",
    "\n",
    "    values = df_fit['90CL_crossing'].loc[good_fit_mask]\n",
    "\n",
    "    sl = SortedList()\n",
    "    medians = []\n",
    "    for n, v in enumerate(values):\n",
    "        sl.add(v)\n",
    "        if v % 2 == 0:  # even\n",
    "            medians.append(sl[n//2])\n",
    "        else:  # odd\n",
    "            medians.append((sl[(n-1)//2] + sl[(n+1)//2]) / 2.)\n",
    "        if v % 100 == 0:  \n",
    "            print(medians[-1], ComputeHalflifeFromNumCounts(medians[-1]))\n",
    "\n",
    "    plt.plot(np.arange(len(values)), medians, '-', linewidth=3, label=df.loc[tag, 'bkg_f'])\n",
    "    \n",
    "plt.xlabel('Number of Toys')\n",
    "plt.ylabel('Median Counts')\n",
    "plt.ylim((6.5,10))\n",
    "# plt.legend()\n",
    "plt.grid()\n",
    "sec_ax = plt.gca().secondary_yaxis('right', \n",
    "                            functions=(lambda x: ComputeHalflifeFromNumCounts(x)/1e28, ComputeCountsFromHalflife))\n",
    "sec_ax.set_ylabel(r'Halflife Sensitivity [$\\times 10^{28}$ yrs]')\n",
    "plt.savefig(plotdir / f'Multivar_study_convergence.png', bbox_inches = \"tight\", \n",
    "                transparent=False, facecolor='white', dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d69499",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "display(df[(df.energy_res_f==0.008) & (df.bkg_f==1.0)])\n",
    "display(df[(df.dnn_f==0.15) & (df.bkg_f==1.5)])\n",
    "for tag in df[(df.dnn_f==0.0) & (df.bkg_f==1.0)].index:\n",
    "    print(df.loc[tag][['energy_res_f','TotalROIBkg']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ff763f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for tag in df[(df.energy_res_f==0.011) & (df.bkg_f==1.0)].index:\n",
    "# for tag in ['992C89', ]:\n",
    "    df_fit = load_fit_results(tag)\n",
    "    good_fit_mask = get_good_fit_mask(df_fit)\n",
    "    h = Hist.new.Regular(121, 0, 60, name=\"signal_counts\").Double()\n",
    "    values = df_fit['90CL_crossing'].loc[good_fit_mask]\n",
    "    h.fill(values)\n",
    "#     median = np.median(values)\n",
    "#     df.at[tag, 'median'] = median\n",
    "#     df.at[tag, 'sens'] = ComputeHalflifeFromNumCounts(median)\n",
    "#     print(f'{tag}\\t{median:.3f}\\t{df.at[tag, \"sens\"]:.3e}')\n",
    "    h.plot1d(ax=ax, label=f'{tag}')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('90% CL on signal counts for given toy')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76b9854",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Sensitivity as a function of background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be7d18b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['TotalROIBkgY'] = df['TotalROIBkg']/10.\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "def f(x, A, exponent):\n",
    "    return A * x ** (-exponent)\n",
    "\n",
    "xnew = np.linspace(0.4,3.1,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c31031",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "popt, pcov = curve_fit(f, df.TotalROIBkgY, df.sens_1e28)\n",
    "perr = np.sqrt(np.diag(pcov))\n",
    "# print(popt, perr)\n",
    "\n",
    "sns.scatterplot(data=df, x='TotalROIBkgY', y='sens_1e28', hue='energy_res_f', \n",
    "                    palette='deep', style='bkg_misID', size='bkg_f', alpha=1 )\n",
    "\n",
    "plt.plot(xnew, f(xnew, popt[0], popt[1]), '--', color='gray', \n",
    "         label=u'Fit: $T_{1/2} \\propto B^{'+ f'-({popt[1]:.2f} \\pm {perr[1]:.2f})' + '}$')\n",
    "# Draw uncertainty band\n",
    "# plt.fill_between(xnew, f(xnew, *(popt))*0.95, f(xnew, *(popt))*1.05, color='gray', alpha=0.2, label = '_nolegend_')\n",
    "# plt.fill_between(xnew, f(xnew, *(popt+perr)), f(xnew, *(popt-perr)), color='gray', alpha=0.2, label = '_nolegend_')\n",
    "# plt.fill_between(xnew, f(xnew, popt[0]+perr[0], popt[1]-perr[1]), f(xnew, popt[0]-perr[0], popt[1]+perr[1]), color='gray', alpha=0.2, label = '_nolegend_')\n",
    "\n",
    "plt.axhline(y=1.0, color='lightgray', linestyle='-', linewidth=3,)\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "new_labels = []\n",
    "for k, label in enumerate(labels):\n",
    "    if k in np.arange(1,6):\n",
    "        new_labels.append(f'{float(label)*100:.1f} %')\n",
    "    elif k in np.arange(12,16):\n",
    "        new_labels.append(f'{float(label):.1f} %')\n",
    "    else:\n",
    "        new_labels.append(label)\n",
    "new_labels[0] = \"Energy Resolution\"\n",
    "new_labels[6] = \"Background\\nScaling Factor\"\n",
    "new_labels[11] = \"Topological\\nDiscriminator MisID\"\n",
    "plt.legend(handles, new_labels, bbox_to_anchor=(1.01,1.02), loc=\"upper left\", fontsize=16)\n",
    "\n",
    "plt.xlabel('Total ROI Background [SS cts/(FWHM$\\cdot$2000kg$\\cdot$y)]')\n",
    "plt.ylabel(r'Halflife Sensitivity [$\\times 10^{28}$ yrs]')\n",
    "plt.tick_params(axis='both', which='major', direction='in', reset=True)\n",
    "\n",
    "plt.savefig(plotdir / f'Sensivitity_vs_background.png', bbox_inches = \"tight\", \n",
    "                transparent=False, facecolor='white', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dab59d9",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Grouped and fitted by energy resolution\n",
    "sns.scatterplot(data=df, x='TotalROIBkgY', y='sens_1e28', hue='energy_res_f', palette='deep', s=80 )\n",
    "\n",
    "colors = iter(sns.color_palette('deep'))\n",
    "for e_res in [0.008, 0.01, 0.011, 0.012, 0.014]:\n",
    "    dtemp = df[df['energy_res_f']==e_res]\n",
    "    popt, pcov = curve_fit(f, dtemp.TotalROIBkgY, dtemp.sens_1e28)\n",
    "    perr = np.sqrt(np.diag(pcov))\n",
    "\n",
    "    plt.plot(xnew, f(xnew, popt[0], popt[1]), '-', color=next(colors), \n",
    "             label=u'Fit: $T_{1/2} \\propto B^{'+ f'-({popt[1]:.2f} \\pm {perr[1]:.2f})' + '}$')\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "new_labels = []\n",
    "for label in labels:\n",
    "    if label.replace('.', '', 1).isdigit():\n",
    "        new_labels.append(f'{float(label)*100:.1f} %')\n",
    "    else:\n",
    "        new_labels.append(label)\n",
    "plt.legend(handles, new_labels, title=\"Energy Resolution\", bbox_to_anchor=(1.01,1.02), loc=\"upper left\", fontsize=16)\n",
    "\n",
    "plt.xlabel('Total ROI Background [SS cts/(FWHM$\\cdot$2000kg$\\cdot$y)]')\n",
    "plt.ylabel(r'Halflife Sensitivity [$\\times 10^{28}$ yrs]')\n",
    "plt.tick_params(axis='both', which='major', direction='in', reset=True)\n",
    "plt.ylim(0.8, 1.5)\n",
    "\n",
    "plt.savefig(plotdir / f'Sensivitity_vs_background_groupByERes.png', bbox_inches = \"tight\", \n",
    "                transparent=False, facecolor='white', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69e632c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df, x='TotalROIBkgY', y='sens_1e28', hue='bkg_misID', palette='deep', s=80)\n",
    "\n",
    "colors = iter(sns.color_palette('deep'))\n",
    "for dnn_f in [0., 0.15, 0.177, 0.2]:\n",
    "    dtemp = df[df['dnn_f']==dnn_f]\n",
    "    popt, pcov = curve_fit(f, dtemp.TotalROIBkgY, dtemp.sens_1e28)\n",
    "    perr = np.sqrt(np.diag(pcov))\n",
    "    # print(popt, perr)\n",
    "\n",
    "    plt.plot(xnew, f(xnew, popt[0], popt[1]), '-', color=next(colors), \n",
    "             label=u'Fit: $T_{1/2} \\propto B^{'+ f'-({popt[1]:.2f} \\pm {perr[1]:.2f})' + '}$')\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "new_labels = []\n",
    "for label in labels:\n",
    "    if label.replace('.', '', 1).isdigit():\n",
    "        new_labels.append(f'{float(label):.1f} %')\n",
    "    else:\n",
    "        new_labels.append(label)\n",
    "plt.legend(handles, new_labels, title=\"Background MisID\", bbox_to_anchor=(1.01,1.02), loc=\"upper left\", fontsize=16)\n",
    "\n",
    "plt.xlabel('Total ROI Background [SS cts/(FWHM$\\cdot$2000kg$\\cdot$y)]')\n",
    "plt.ylabel(r'Halflife Sensitivity [$\\times 10^{28}$ yrs]')\n",
    "plt.tick_params(axis='both', which='major', direction='in', reset=True)\n",
    "plt.ylim(0.8, 1.5)\n",
    "\n",
    "plt.savefig(plotdir / f'Sensivitity_vs_background_groupDNNF.png', bbox_inches = \"tight\", \n",
    "                transparent=False, facecolor='white', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda4bf36",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df['ROIbkg'] = 0.1 * (df['Num_Vessel_U238'] + df['Num_Internals_U238'] + df['Num_Rn222'] + df['Num_Far'])\n",
    "df['ROIbkg'] = 0.1 * (df['Num_Vessel_Th232'] + df['Num_Internals_Th232'] + df['Num_B8nu'] + df['Num_Xe137_and_Ar42'])\n",
    " \n",
    "popt, pcov = curve_fit(f, df.ROIbkg, df.sens_1e28)\n",
    "perr = np.sqrt(np.diag(pcov))\n",
    "# print(popt, perr)\n",
    "\n",
    "# sns.scatterplot(data=df, x='TotalROIBkgYkeV', y='sens_1e28', hue='bkg_misID', \n",
    "#                 palette='deep', style='energy_res_f', size='bkg_f', alpha=1 )\n",
    "\n",
    "sns.scatterplot(data=df, x='ROIbkg', y='sens_1e28', hue='energy_res_f', \n",
    "                    palette='deep', style='bkg_misID', size='bkg_f', alpha=1 )\n",
    "\n",
    "# xnew = np.linspace(0.4,3.1,1000)\n",
    "plt.plot(xnew/12, f(xnew/12, popt[0], popt[1]), '--', color='gray', \n",
    "         label=u'Fit: $T_{1/2} \\propto B^{'+ f'-({popt[1]:.2f} \\pm {perr[1]:.3f})' + '}$')\n",
    "# Draw uncertainty band\n",
    "# plt.fill_between(xnew/12, f(xnew/12, *(popt)*0.95), f(xnew/12, *(popt)*1.05), color='gray', alpha=0.2, label = '_nolegend_')\n",
    "# plt.fill_between(xnew/15, f(xnew/15, *(popt+perr)), f(xnew/15, *(popt-perr)), color='gray', alpha=0.2, label = '_nolegend_')\n",
    "# plt.fill_between(xnew/15, f(xnew/15, popt[0]+perr[0], popt[1]-perr[1]), f(xnew/15, popt[0]-perr[0], popt[1]+perr[1]), color='gray', alpha=0.2, label = '_nolegend_')\n",
    "\n",
    "# plt.axhline(y=1.0, color='lightgray', linestyle='-', linewidth=3,)\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "# new_labels = []\n",
    "# for k, label in enumerate(labels):\n",
    "#     if k in np.arange(1,5):\n",
    "#         new_labels.append(f'{float(label)*100:.1f} %')\n",
    "#     elif k in np.arange(12,16):\n",
    "#         new_labels.append(f'{float(label):.1f} %')\n",
    "#     else:\n",
    "#         new_labels.append(label)\n",
    "# new_labels[0] = \"Energy Resolution\"\n",
    "# new_labels[6] = \"Background\\nScaling Factor\"\n",
    "# new_labels[11] = \"Topological\\nDiscriminator MisID\"\n",
    "plt.legend(handles, labels, bbox_to_anchor=(1.01,1.02), loc=\"upper left\", fontsize=16)\n",
    "\n",
    "plt.xlabel(r'ROI Background ($^{232}$Th, $\\nu$, $^{137}$Xe, $^{42}$Ar) [SS cts/(FWHM$\\cdot$2000kg$\\cdot$y)]')\n",
    "plt.ylabel(r'Halflife Sensitivity [$\\times 10^{28}$ yrs]')\n",
    "plt.tick_params(axis='both', which='major', direction='in', reset=True)\n",
    "\n",
    "# plt.savefig(plotdir / f'Sensivitity_vs_background-mod.png', bbox_inches = \"tight\", \n",
    "#                 transparent=False, facecolor='white', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c452ee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nEXO VirtualEnv",
   "language": "python",
   "name": "nexo_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
